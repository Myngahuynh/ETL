{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ac29880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO, BytesIO\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51849c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapter Layer\n",
    "\n",
    "##read file csv\n",
    "def read_csv_to_df(bucket, key, decoding = 'utf-8', sep = ','):\n",
    "    csv_obj = bucket.Object(key=key).get().get('Body').read().decode(decoding)\n",
    "    data = StringIO(csv_obj)\n",
    "    df = pd.read_csv(data, delimiter=sep)\n",
    "    return df\n",
    "\n",
    "## (write df to s3 *file parquet)\n",
    "def write_df_to_s3(bucket, df, key):\n",
    "    out_buffer = BytesIO()\n",
    "    df.to_parquet(out_buffer, index=False)\n",
    "    bucket.put_object(Body=out_buffer.getvalue(), Key=key)\n",
    "    return True\n",
    "\n",
    "# def list_files_in_prefix(bucket, prefix):\n",
    "#     files = [obj.key for obj in bucket.objects.filter(Prefix=prefix)]\n",
    "#     return files\n",
    "\n",
    "def return_objects(bucket, arg_date, src_format):\n",
    "    min_date = datetime.strptime(arg_date, src_format).date() - timedelta(days=1)\n",
    "    objects = [obj.key for obj in bucket.objects.all() if datetime.strptime(obj.key.split('/')[1], src_format).date() >= min_date]\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05c77de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application Layer\n",
    "\n",
    "def extract(bucket, objects):\n",
    "    df = pd.concat([read_csv_to_df(bucket, obj) for obj in objects], ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def transform_report1(df, columns, arg_date):\n",
    "    df = df.loc[:, columns]\n",
    "    df.dropna(inplace=True)\n",
    "    df['opening_price'] = df.sort_values(by=['Time']).groupby(['ISIN', 'Date'])['StartPrice'].transform('first')\n",
    "    df['closing_price'] = df.sort_values(by=['Time']).groupby(['ISIN', 'Date'])['StartPrice'].transform('last')\n",
    "    df = df.groupby(['ISIN', 'Date'], as_index=False).agg(opening_price_eur=('opening_price', 'min'), closing_price_eur=('closing_price', 'min'), minimum_price_eur=('MinPrice', 'min'), maximum_price_eur=('MaxPrice', 'max'), daily_traded_volume=('TradedVolume', 'sum'))\n",
    "    df['prev_closing_price'] = df.sort_values(by=['Date']).groupby(['ISIN'])['closing_price_eur'].shift(1)\n",
    "    df['change_prev_closing_%'] = (df['closing_price_eur'] - df['prev_closing_price']) / df['prev_closing_price'] * 100\n",
    "    df.drop(columns=['prev_closing_price'], inplace=True)\n",
    "    df = df.round(decimals=2)\n",
    "    df = df[df.Date >= arg_date]\n",
    "    return df\n",
    "\n",
    "def load(bucket, df, trg_key, trg_format):\n",
    "    key = trg_key + datetime.today().strftime(\"%Y%m%d_%H%M%S\") + trg_format\n",
    "    write_df_to_s3(bucket, df, key)\n",
    "    return True\n",
    "\n",
    "def etl_report1(src_bucket, trg_bucket, objects, columns, arg_date, trg_key, trg_format):\n",
    "    df = extract(src_bucket, objects)\n",
    "    df = transform_report1(df, columns, arg_date)\n",
    "    load(trg_bucket, df, trg_key, trg_format)\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a2ea89b-d357-4829-9237-3f4bcac01178",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2202301978.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    return_date_list = (min_date +timedelta(days=x)).strftime(src_format) for x in range(0, (today.start).days +1)\u001b[0m\n\u001b[1;37m                                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Application (not core)\n",
    "\n",
    "def return_date_list(bucket, arg_date, src_format):\n",
    "    min_date = datetime.strptime(arg_date, src_format).date() - timedelta(days=1)\n",
    "    today = datetime.today().date()\n",
    "    return_date_list = (min_date +timedelta(days=x)).strftime(src_format) for x in range(0, (today.start).days +1)\n",
    "    return return_date_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015346ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function entrypoint\n",
    "\n",
    "def main():\n",
    "    # Parameters/Configurations\n",
    "    # Later read config\n",
    "    arg_date = '2022-01-04'\n",
    "    src_format = '%Y-%m-%d'\n",
    "    src_bucket = 'demo-s3-nhhung2'\n",
    "    trg_bucket = 'xetra-112233'\n",
    "    columns = ['ISIN', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice', 'EndPrice', 'TradedVolume']\n",
    "    trg_key = 'xetra_daily_report_'\n",
    "    trg_format = '.parquet'\n",
    "    \n",
    "    # Init\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket_src = s3.Bucket(src_bucket)\n",
    "    bucket_trg = s3.Bucket(trg_bucket)\n",
    "    \n",
    "    # run application\n",
    "    date_list = return_date_list(bucket_src, arg_date, src_format)\n",
    "    # objects = return_objects(bucket_src, arg_date, src_format)\n",
    "    etl_report1(bucket_src, bucket_trg, objects, columns, arg_date, trg_key, trg_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2fe394",
   "metadata": {},
   "source": [
    "## Reading the uploaded file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_bucket = 'xetra-112233'\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_trg = s3.Bucket(trg_bucket)\n",
    "for obj in bucket_trg.objects.all():\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac0c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prq_obj = bucket_trg.Object(key='xetra_daily_report_20231218_160058.parquet').get().get('Body').read()\n",
    "data = BytesIO(prq_obj)\n",
    "df_report = pd.read_parquet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c007b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670c187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
